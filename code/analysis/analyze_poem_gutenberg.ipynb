{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from xml.etree import cElementTree as ET\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from analysis_code.analyze_corpus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "barwidth = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''json files'''\n",
    "exampleFile = '/home/dashi/lulu/corpus/gutenberg-poem/gutenberg-poetry-example.ndjson'\n",
    "corpus = '/home/dashi/lulu/corpus/gutenberg-poem/gutenberg-poetry-v001.ndjson'\n",
    "\n",
    "'''converted into txt articles'''\n",
    "sampleDir = '/home/dashi/lulu/corpus/gutenberg-poem/sample/'   \n",
    "articleBreakDir = '/home/dashi/lulu/corpus/gutenberg-poem/gutenberg-artbreak/'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "emos = loadEmotionWords('/home/dashi/lulu/corpus/NRC-Emotion-Lexicon-v0.92/Generated-EmotionWords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_files = glob.glob(articleBreakDir + '*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Sentence length histogram\n",
    "# error: doc input string cannot succeed 1 million characters\n",
    "# problem: non-edited opinion text can have long and publish unaccepted sentence structures\n",
    "# '''\n",
    "# read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "# counter = Counter('')\n",
    "# i = 0\n",
    "\n",
    "# for infile in read_files:\n",
    "#     print('i : ' + str(i))\n",
    "#     with open(infile, 'r', errors='replace') as f:\n",
    "#         text = f.read()\n",
    "#         doc = nlp(text)\n",
    "#         counter += analyzeSentence(doc) \n",
    "#         i += 1\n",
    "        \n",
    "# plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "# labels, values = rankCounter(counter)\n",
    "# indexes = np.arange(len(labels))\n",
    "# width = 1\n",
    "# plt.bar(indexes, values, width)\n",
    "# plt.xticks(indexes + width * 0.5, labels)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Punctuation histogram\n",
    "'''\n",
    "\n",
    "# read_files = glob.glob(\"/home/luluvyd/corpus/aclImdb/train/pos/*.txt\")\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counter = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counter += analyzePunctuation(doc) \n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counter)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pronoun histogram\n",
    "error: doc input string cannot succeed 1 million characters\n",
    "problem: non-edited opinion text can have long and publish unaccepted sentence structures\n",
    "'''\n",
    "\n",
    "# read_files = glob.glob(\"/home/luluvyd/corpus/aclImdb/train/pos/*.txt\")\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counter = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counter += analyzePronounCategories(doc) \n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counter)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Verb histogram\n",
    "error: doc input string cannot succeed 1 million characters\n",
    "problem: non-edited opinion text can have long and publish unaccepted sentence structures\n",
    "'''\n",
    "\n",
    "# read_files = glob.glob(\"/home/luluvyd/corpus/aclImdb/train/pos/*.txt\")\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counter = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counter += analyzeVerb(doc) \n",
    "        i += 1\n",
    "        print(i)\n",
    "        \n",
    "        \n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counter)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Verb category histogram\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "CounterAct = Counter('')\n",
    "CounterLink = Counter('')\n",
    "CounterHelp = Counter('')\n",
    "CounterHM = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        a, b, c, d = analyzeVerbs(doc) \n",
    "        CounterAct += a\n",
    "        CounterLink += b\n",
    "        CounterHelp += c\n",
    "        CounterHM += d\n",
    "        print('i : ' + str(i))  \n",
    "        i += 1\n",
    "    \n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(CounterAct)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(CounterLink)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(CounterHelp)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(CounterHM)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Emotion words histogram\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "counterEmos = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterEmos += analyzeEmotionWords(doc, emos) \n",
    "        i += 1\n",
    "    \n",
    "print(counterEmos)\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterEmos)\n",
    "indexes = np.arange(len(labels))g\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Emotion words histogram\n",
    "'''  \n",
    "read_files = glob.glob(articleBreakDir + '*.txt')\n",
    "N = len(read_files)\n",
    "countersEmos, sizesEmos = docTermFreq(read_files, emos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(countersEmos))\n",
    "print(len(sizesEmos))\n",
    "\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(countersEmos[0])\n",
    "values = [v*1.0/sizesEmos[1] for v in values]\n",
    "indexes = np.arange(len(labels)) \n",
    "plt.bar(indexes, values, barwidth)\n",
    "plt.xticks(indexes + barwidth * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfsEmos = termFreq(countersEmos, sizesEmos)\n",
    "counterEmos, szEmos = docFreq(countersEmos)\n",
    "idfEmos = invDocFreq(counterEmos, szEmos)\n",
    "tiEmos = tfIdf(tfsEmos, idfEmos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tiEmos)) \n",
    "d = sortByValue(tiEmos[1])\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = list(d.keys())[:20], list(d.values())[:20]\n",
    "indexes = np.arange(len(labels)) \n",
    "plt.bar(indexes, values, barwidth)\n",
    "plt.xticks(indexes + barwidth * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "result = {k: v for k, v in sorted(idfEmos.items(), key=lambda item: item[1])}\n",
    "labels = list(result.keys())[:20]\n",
    "values = list(result.values())[:20]\n",
    "indexes = np.arange(len(labels)) \n",
    "plt.bar(indexes, values, barwidth)\n",
    "plt.xticks(indexes + barwidth * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Verb category histogram\n",
    "''' \n",
    "countersAct = []\n",
    "countersLink = []\n",
    "countersHelp = [] \n",
    "countersHM = []\n",
    "\n",
    "szAct = []\n",
    "szLink = []\n",
    "szHelp = []\n",
    "szHM = []\n",
    "N = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    if (N > 50):\n",
    "        break\n",
    "    s = os.path.getsize(infile) \n",
    "    f = s/1000000\n",
    "    m = s % 1000000\n",
    "    d = 0\n",
    "    if m > 0: \n",
    "        d += 1\n",
    "    if f > 0: \n",
    "        d += int(f)\n",
    "        \n",
    "    if d == 0: \n",
    "        continue \n",
    "    elif d == 1: \n",
    "        N += 1\n",
    "        with open(infile, 'r', errors='replace') as f:\n",
    "            text = f.read()\n",
    "            doc = nlp(text)\n",
    "            a, b, c, d = analyzeVerbs(doc) \n",
    "            countersAct.append(a)\n",
    "            countersLink.append(b) \n",
    "            countersHelp.append(c) \n",
    "            countersHM.append(d) \n",
    "        \n",
    "            szAct.append(sum(a.values()))\n",
    "            szLink.append(sum(b.values()))\n",
    "            szHelp.append(sum(c.values()))\n",
    "            szHM.append(sum(d.values()))\n",
    "    else:    \n",
    "        with open(infile, 'r', errors='replace') as f:\n",
    "            text = f.read()\n",
    "            m = int(len(text)/d)\n",
    "            for i in range(d):\n",
    "                short = text[i*m:(i+1)*m]\n",
    "                doc = nlp(short)\n",
    "                a, b, c, d = analyzeVerbs(doc) \n",
    "                countersAct.append(a)\n",
    "                countersLink.append(b) \n",
    "                countersHelp.append(c) \n",
    "                countersHM.append(d) \n",
    "                \n",
    "                szAct.append(sum(a.values()))\n",
    "                szLink.append(sum(b.values()))\n",
    "                szHelp.append(sum(c.values()))\n",
    "                szHM.append(sum(d.values()))\n",
    "                N += 1\n",
    "    print(N)\n",
    "        \n",
    "print(sum(np.array(szAct)))\n",
    "print(sum(np.array(szLink)))\n",
    "print(sum(np.array(szHelp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Verb category histogram\n",
    "''' \n",
    "countersAct = []\n",
    "countersLink = []\n",
    "countersHelp = [] \n",
    "countersHM = []\n",
    "\n",
    "szAct = []\n",
    "szLink = []\n",
    "szHelp = []\n",
    "szHM = []\n",
    "N = 0\n",
    "\n",
    "for infile in read_files: \n",
    "    s = os.path.getsize(infile) \n",
    "    if s < 1000000:  \n",
    "        print(s)\n",
    "        N += 1\n",
    "        with open(infile, 'r', errors='replace') as f:\n",
    "            text = f.read()\n",
    "            doc = nlp(text)\n",
    "            a, b, c, d = analyzeVerbs(doc) \n",
    "            countersAct.append(a)\n",
    "            countersLink.append(b) \n",
    "            countersHelp.append(c) \n",
    "            countersHM.append(d) \n",
    "        \n",
    "            szAct.append(sum(a.values()))\n",
    "            szLink.append(sum(b.values()))\n",
    "            szHelp.append(sum(c.values()))\n",
    "            szHM.append(sum(d.values()))\n",
    "        \n",
    "print(sum(np.array(szAct)))\n",
    "print(sum(np.array(szLink)))\n",
    "print(sum(np.array(szHelp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([sum(np.array(szAct)), sum(np.array(szLink)), sum(np.array(szHelp))])\n",
    "# values = x\n",
    "values = x*1.0/sum(x)\n",
    "labels = [\"action\", \"linking\", \"helping\"]\n",
    "indexes = np.arange(len(labels))\n",
    "plt.figure(num=None, figsize=(4, 3), dpi=80, facecolor='w', edgecolor='k') \n",
    "plt.bar(indexes, values, barwidth)\n",
    "plt.xticks(indexes + barwidth * 0.1, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pronoun histogram\n",
    "Percentage of punctuation out of total number of words\n",
    "''' \n",
    "countersPron = []\n",
    "counterPron = Counter()\n",
    "N = 0 \n",
    "\n",
    "for infile in read_files: \n",
    "    s = os.path.getsize(infile) \n",
    "    if s < 1000000: \n",
    "        N += 1\n",
    "        with open(infile, 'r', errors='replace') as f:\n",
    "            text = f.read()\n",
    "            doc = nlp(text)\n",
    "            c = analyzePronoun(doc)\n",
    "            counterPron += c\n",
    "            countersPron.append(c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterPron)\n",
    "values = np.array(values)*1.0/sum(counterPron.values())\n",
    "indexes = np.arange(len(labels)) \n",
    "plt.bar(indexes, values, barwidth)\n",
    "plt.xticks(indexes + barwidth * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterPron)\n",
    "values = np.array(values)\n",
    "indexes = np.arange(len(labels)) \n",
    "plt.bar(indexes, values, barwidth)\n",
    "plt.xticks(indexes + barwidth * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pronoun, personal histogram\n",
    "Percentage of punctuation out of total number of words\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterPronPRP = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterPronPRP += analyzePronounPRP(doc) \n",
    "        i += 1\n",
    "    \n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterPronPRP)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Verb category histogram\n",
    "Percentage of punctuation out of total number of words\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterVerbAct = Counter('')\n",
    "counterVerbLink = Counter('')\n",
    "counterVerbHelp = Counter('')\n",
    "counterVerbHM = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        a, b, c, d = analyzeVerbs(doc) \n",
    "        counterVerbAct += a\n",
    "        counterVerbLink += b\n",
    "        counterVerbHelp += c\n",
    "        counterVerbHM += d\n",
    "        i += 1\n",
    "    \n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterVerbAct)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CounterVerbCategories = Counter({'Action' : sumCounter(counterVerbAct), \n",
    "                         'Linking' : sumCounter(counterVerbLink), \n",
    "                         'Helping' : sumCounter(counterVerbHelp)})\n",
    "Total = sumCounter(CounterVerbCategories)\n",
    "\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(CounterVerbCategories)\n",
    "values = [int(float(v)*100/Total) for v in values]\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
