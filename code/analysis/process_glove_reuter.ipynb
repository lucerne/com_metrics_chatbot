{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from xml.etree import cElementTree as ET\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''name definition'''\n",
    "directory = '/home/luluvyd/corpus/Reuters21578/'\n",
    "glove_input = 'reuter_combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "def cleanText(doc):\n",
    "    '''create an input for training a GloVe embedding by getting rid of all except alphabet words\n",
    "    input : SpaCy doc \n",
    "    return : text input for GloVe\n",
    "    '''\n",
    "    txt = \"\"\n",
    "    for token in doc:\n",
    "        if token.text.isalpha(): \n",
    "            txt += token.text + \" \"\n",
    "    return txt.lower()\n",
    "\n",
    "def getBodies(file): \n",
    "    ''' Strip XML tag and get the text between BODY tag\n",
    "    input: file handler for reading  \n",
    "    return : body text of the XML \n",
    "    '''\n",
    "    line = file.readline()\n",
    "    bodies = []\n",
    "    text = \"\"\n",
    "    while line:\n",
    "        line = file.readline()\n",
    "        if \"<BODY>\" in line: \n",
    "            idx = line.find(\"<BODY>\")\n",
    "            text = line[idx + len(\"<BODY>\"):]\n",
    "            \n",
    "            line = file.readline()\n",
    "            while \"reuter\" not in line.lower():  \n",
    "                text += line \n",
    "                line = file.readline()\n",
    "\n",
    "            bodies.append(text)\n",
    "            text = \"\"\n",
    "            \n",
    "    return bodies\n",
    "\n",
    "def getGloveInput(bodies): \n",
    "    '''combine content of a reuter file to create glove input'''\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    parsed = [nlp(b) for b in bodies]\n",
    "    cleaned = [cleanText(p) for p in parsed]\n",
    "    return cleaned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStatistics(text):\n",
    "    '''combine text including nonalphabet words'''\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    \n",
    "    \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "make Glove input from corpus\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    read_files = glob.glob(\"/home/luluvyd/corpus/Reuters21578/*.sgm\")\n",
    "    text = []\n",
    "    for f in read_files:\n",
    "        with open(f, 'r', errors='replace') as infile:\n",
    "            text += getBodies(infile)\n",
    "            infile.close()\n",
    "    allText = ' '.join(text)\n",
    "    getStatistics(allText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "make NLP statistics\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    \n",
    "#     read_files = glob.glob(\"/home/luluvyd/corpus/Reuters21578/*.sgm\")\n",
    "    read_files = glob.glob(\"/home/luluvyd/corpus/Reuters21578/reut2-000.sgm\")\n",
    "    \n",
    "    with open(\"/home/luluvyd/corpus/Reuters21578/combined_reuter.txt\", \"w\") as outfile:\n",
    "        for f in read_files:\n",
    "            with open(f, 'r', errors='replace') as infile:\n",
    "                bodies = getBodies(infile)\n",
    "                statistics = getStatistics(bodies)\n",
    "                for c in cleaned: \n",
    "                    outfile.write(c)\n",
    "            infile.close()\n",
    "    outfile.close()      \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
