{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from analysis_code.analyze_corpus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = '/home/luluvyd/corpus/aclImdb/sample/'\n",
    "filename = '/home/luluvyd/examples/data/9_4.txt'\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-55cac989926e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparsed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'This is an awesome sentence. Where is the cat?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzePOS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luluvyd/com_metrics_chatbot/code/analysis_code/analyze_corpus.py\u001b[0m in \u001b[0;36manalyzePOS\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0mof\u001b[0m \u001b[0mPOS\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     '''\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "parsed_text = 'This is an awesome sentence. Where is the cat?'\n",
    "doc = nlp(parsed_text)\n",
    "counter = analyzePOS(doc)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '/home/luluvyd/examples/data/example_out.json'\n",
    "# f = open(filename, 'w+')\n",
    "with open(filename, 'w+') as f:\n",
    "    json.dump(counter, f)\n",
    "    \n",
    "# for key, val in dict(counter).items():\n",
    "#     f.writerow([key, val])\n",
    "# f.close()\n",
    "\n",
    "\n",
    "# with open('data.json', 'w') as fp:\n",
    "#     json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. Where is the cat?'\n",
    "doc = nlp(parsed_text)\n",
    "counter = analyzeSentence(doc)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. Where is the cat?'\n",
    "doc = nlp(parsed_text)\n",
    "counter = analyzeWordLength(doc)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. Where is the cat?'\n",
    "doc = nlp(parsed_text)\n",
    "counter = analyzePunctuation(doc)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. Where is the cat?'\n",
    "doc = nlp(parsed_text)\n",
    "counterPos = analyzePOS(doc)\n",
    "counterPunc = analyzePunctuation(doc)\n",
    "print(sumCounter(counterPunc) / sumCounter(counterPos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. My is better. Their food is worse. It is it. Who is good? What is in him?'\n",
    "doc = nlp(parsed_text)\n",
    "counterPunc = analyzePronoun(doc)\n",
    "print(counterPunc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. My is better. Their food is worse. It is it. Who is good? What is in him?'\n",
    "doc = nlp(parsed_text)\n",
    "counterPRP = analyzePronounPRP(doc)\n",
    "print(counterPRP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. My is better. Their food is worse. It is it. Who is good? What is in him?'\n",
    "doc = nlp(parsed_text)\n",
    "counterPRPD = analyzePronounPRPD(doc)\n",
    "print(counterPRPD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. My is better. Their food is worse. It is it. Who is good? What is in him?'\n",
    "doc = nlp(parsed_text)\n",
    "counterPWP = analyzePronounWP(doc)\n",
    "print(counterPWP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. My is better. Their food is worse. It is it. Who is good? What is in him?'\n",
    "doc = nlp(parsed_text)\n",
    "counterPWPD = analyzePronounWPD(doc)\n",
    "print(counterPWPD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. My is better. Their food is worse. It is it. Who is good? What is in him?'\n",
    "doc = nlp(parsed_text)\n",
    "counterPCat = analyzePronounCategories(doc)\n",
    "print(counterPCat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_text = 'This is an awesome sentence. I am running. It rains.'\n",
    "doc = nlp(parsed_text)\n",
    "counterVerb = analyzeVerb(doc)\n",
    "print(counterVerb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels, values = rankCounter(counter)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels, values = rankCounter(counter)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "        nlp = spacy.load('en_core_web_md')\n",
    "        doc = nlp(text)\n",
    "        counter = analyzePOS(doc)\n",
    "        \n",
    "        plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "        labels, values = rankCounter(counter)\n",
    "        indexes = np.arange(len(labels))\n",
    "        width = 1\n",
    "        plt.bar(indexes, values, width)\n",
    "        plt.xticks(indexes + width * 0.5, labels)\n",
    "        plt.show()\n",
    "    f.close()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "POS histogram\n",
    "error: doc input string cannot succeed 1 million characters\n",
    "problem: iterating over text is too slow, parallelize\n",
    "'''\n",
    "\n",
    "# read_files = glob.glob(\"/home/luluvyd/corpus/aclImdb/train/pos/*.txt\")\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counter = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        counter += analyzePOS(text) \n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counter)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Sentence length histogram\n",
    "error: doc input string cannot succeed 1 million characters\n",
    "problem: non-edited opinion text can have long and publish unaccepted sentence structures\n",
    "'''\n",
    "\n",
    "# read_files = glob.glob(\"/home/luluvyd/corpus/aclImdb/train/pos/*.txt\")\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counter = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counter += analyzeSentence(doc) \n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counter)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Word lengths histogram \n",
    "error: doc input string cannot succeed 1 million characters\n",
    "'''\n",
    "\n",
    "# read_files = glob.glob(\"/home/luluvyd/corpus/aclImdb/train/pos/*.txt\")\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterWord = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterWord += analyzeWordLength(doc) \n",
    "        i += 1\n",
    "\n",
    "mean = sum([k*v for k, v in counterWord.items()]) / sumCounter(counterWord)\n",
    "print('average word lengths is : ' + str(mean))\n",
    "\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterWord)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Punctuation histogram\n",
    "Percentage of punctuation out of total number of words\n",
    "'''\n",
    "\n",
    "# read_files = glob.glob(\"/home/luluvyd/corpus/aclImdb/train/pos/*.txt\")\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterPun = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterPun += analyzePunctuation(doc) \n",
    "        i += 1\n",
    "pert = sumCounter(counterPun) / sumCounter(counterWord)*100\n",
    "print('percent of puncutation symbol is : ' + str(pert))\n",
    "        \n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterPun)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Punctuation histogram\n",
    "Percentage of punctuation out of total number of words\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterPron = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterPron += analyzePronoun(doc) \n",
    "        i += 1\n",
    "    \n",
    "print(counterPron)\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterPron)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Pronoun, personal histogram\n",
    "Percentage of punctuation out of total number of words\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterPronPRP = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterPronPRP += analyzePronounPRP(doc) \n",
    "        i += 1\n",
    "    \n",
    "print(counterPron)\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterPronPRP)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "pronoun, possessive histogram\n",
    "Percentage of punctuation out of total number of words\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterPronPRPD = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterPronPRPD += analyzePronounPRPD(doc) \n",
    "        i += 1\n",
    "    \n",
    "print(counterPronPRPD)\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterPronPRPD)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "pronoun, possessive histogram\n",
    "Percentage of punctuation out of total number of words\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterPronWP = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterPronWP += analyzePronounWP(doc) \n",
    "        i += 1\n",
    "    \n",
    "print(counterPronWP)\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterPronWP)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "wh-pronoun, possessive histogram\n",
    "Percentage of punctuation out of total number of words\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterPronWPD = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterPronWPD += analyzePronounWPD(doc) \n",
    "        i += 1\n",
    "    \n",
    "print(counterPronWPD)\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterPronWPD)\n",
    "if labels and values:\n",
    "    indexes = np.arange(len(labels))\n",
    "    width = 1\n",
    "    plt.bar(indexes, values, width)\n",
    "    plt.xticks(indexes + width * 0.5, labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "4 pronoun categories histogram\n",
    "Percentage of punctuation out of total number of words\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterPronCat = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterPronCat += analyzePronounCategories(doc) \n",
    "        i += 1\n",
    "    \n",
    "print(counterPronCat)\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterPronCat)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Verb root words histogram\n",
    "'''\n",
    "read_files = glob.glob(directory + '*.txt')\n",
    "\n",
    "counterVerbRoot = Counter('')\n",
    "i = 0\n",
    "\n",
    "for infile in read_files:\n",
    "    print('i : ' + str(i))\n",
    "    with open(infile, 'r', errors='replace') as f:\n",
    "        text = f.read()\n",
    "        doc = nlp(text)\n",
    "        counterVerbRoot += analyzeVerb(doc) \n",
    "        i += 1\n",
    "    \n",
    "print(counterVerbRoot)\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "labels, values = rankCounter(counterVerbRoot)\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
